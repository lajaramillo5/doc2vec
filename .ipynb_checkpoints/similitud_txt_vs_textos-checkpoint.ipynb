{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models as gsm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruta a los archivos del corpus de entrada\n",
    "train_corpus=\"./doc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['texto1.txt', 'texto2.txt', 'texto3.txt', 'texto4.txt', 'texto5.txt', 'texto6.txt', 'texto7.txt', 'texto8.txt']\n",
      "model is saved\n"
     ]
    }
   ],
   "source": [
    "# etiquetar los archivos de texto\n",
    "class DocIterator(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield TaggedDocument(words=doc.split(), tags=[self.labels_list[idx]])\n",
    "\n",
    "docLabels = [f for f in listdir(train_corpus) if f.endswith('.txt')]\n",
    "print(docLabels)\n",
    "data = []\n",
    "for doc in docLabels:\n",
    "    data.append(open(join(train_corpus, doc), 'r').read())\n",
    "    \n",
    "it = DocIterator(data, docLabels)\n",
    "#train doc2vec model\n",
    "model = gsm.Doc2Vec(vector_size=300, window=10, min_count=1, workers=11,alpha=0.025, min_alpha=0.025) # use fixed learning rate\n",
    "model.build_vocab(it)\n",
    "model.train(it, total_examples=len(doc), epochs=20)\n",
    "\n",
    "\n",
    "model.save(\"paper.model\")\n",
    "\n",
    "print(\"model is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is loaded\n"
     ]
    }
   ],
   "source": [
    "# cargando el modelo\n",
    "model=\"paper.model\"\n",
    "m=gsm.Doc2Vec.load(model)\n",
    "print(\"model is loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('texto6.txt', 0.9999697804450989),\n",
       " ('texto5.txt', 0.9999686479568481),\n",
       " ('texto4.txt', 0.9999674558639526)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ruta de acceso a los archivos de prueba\n",
    "test_paper=\"./textos/S0210-48062009000300013-4.txt\"\n",
    "new_test = open(join(test_paper), 'r').read().split()\n",
    "#print(new_test)\n",
    "inferred_docvec = m.infer_vector(new_test)\n",
    "m.docvecs.most_similar([inferred_docvec], topn=3)\n",
    "#print('%s:\\n %s' % (model, m.docvecs.most_similar(positive=[inferred_docvec], topn=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
